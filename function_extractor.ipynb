{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime\n",
    "import ssl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import csv\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import json\n",
    "import subprocess\n",
    "import glob\n",
    "import requests\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloading source content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_content(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find all the line numbers that the functions begins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the line numbers that the functions begins\n",
    "def get_line_numbers(filename,lang_type):\n",
    "    # found = False\n",
    "    #cmd = \"ctags -x --c-kinds=fp \" + filename + \" | grep \" + funcname\n",
    "    cmd = \"ctags -x --\"+lang_type+\"-kinds=f \" + filename\n",
    "\n",
    "    output = subprocess.getoutput(cmd)\n",
    "    lines = output.splitlines()\n",
    "    line_nums = []\n",
    "    for line in lines:\n",
    "        line = line.split(\" \")\n",
    "        char = list(filter(None, line))\n",
    "        line_num = char[2]\n",
    "        line_nums.append(int(line_num))\n",
    "    return line_nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_file(filename, line_num):\n",
    "    # print(\"opening \" + filename + \" on line \" + str(line_num))\n",
    "\n",
    "    code = \"\"\n",
    "    cnt_braket = 0\n",
    "    found_start = False\n",
    "    found_end = False\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if(i >= (line_num - 1)):\n",
    "                code += line\n",
    "\n",
    "                if (not line.startswith(\"//\")) and line.count(\"{\") > 0:\n",
    "                    found_start = True\n",
    "                    cnt_braket += line.count(\"{\")\n",
    "\n",
    "                if (not line.startswith(\"//\")) and line.count(\"}\") > 0:\n",
    "                    cnt_braket -= line.count(\"}\")\n",
    "\n",
    "                if cnt_braket == 0 and found_start == True:\n",
    "                    found_end = True\n",
    "                    return code, i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_num(filename):\n",
    "    diff_start_lines = []\n",
    "    with open(filename, \"r\") as patch:\n",
    "        for i, line in enumerate(patch):\n",
    "            if line.startswith(\"@@ \"):\n",
    "                if not i == 0:\n",
    "                    diff_start_lines.append(i)\n",
    "        diff_start_lines.append(i+1)\n",
    "    return diff_start_lines\n",
    "\n",
    "def get_enumerate(filename):\n",
    "    patch = open(filename, \"r\")\n",
    "    return enumerate(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_diff_information(filename, diff_start_lines):\n",
    "    block_num = 0\n",
    "    archor = []\n",
    "    count = 0\n",
    "    for diff_start_line in diff_start_lines:\n",
    "        # reset some values\n",
    "        count += 1\n",
    "        minus_count = 0\n",
    "        plus_count = 0\n",
    "        before = None\n",
    "        after = None\n",
    "        start_line_num = None\n",
    "        minus_pos = []\n",
    "        plus_pos = []\n",
    "        patch = []\n",
    "        for j, l in get_enumerate(filename):\n",
    "            if count == len(diff_start_lines):\n",
    "                if j == diff_start_line - 1:\n",
    "                    patch.append(l)\n",
    "                    if l.startswith(\"-\"):\n",
    "                        minus_count += 1\n",
    "                        minus_pos.append(j - start_line_num)\n",
    "                    if l.startswith(\"+\"):\n",
    "                        plus_count += 1\n",
    "                        plus_pos.append(j - start_line_num)\n",
    "                    block_num = j\n",
    "                    before = list(map(int, before))\n",
    "                    after = list(map(int, after))\n",
    "                    if len(archor) == 0:\n",
    "                        archor.append(\n",
    "                            [before, after, minus_count, plus_count, minus_pos, plus_pos, patch, after[0], minus_count,\n",
    "                             0])\n",
    "                    else:\n",
    "                        diff_value = archor[-1][8] + minus_count\n",
    "                        insert_after = after[0] + archor[-1][8]\n",
    "                        last_end = archor[-1][1][0] + archor[-1][1][1] - 1\n",
    "                        archor.append([before, after, minus_count, plus_count, minus_pos, plus_pos, patch, insert_after,\n",
    "                                       diff_value, last_end])\n",
    "                    break\n",
    "\n",
    "                if block_num <= j < diff_start_line - 1:\n",
    "                    patch.append(l)\n",
    "                    if l.startswith(\"@@ \"):\n",
    "                        start_line_num = j\n",
    "                        pos = l.find(\"@@ \")\n",
    "                        end = l.find(\" @@ \")\n",
    "                        modified = l[pos + 3:end]\n",
    "                        modified = modified.split(\" \")\n",
    "                        before = modified[0]\n",
    "                        before = before.replace(\"-\", \"\")\n",
    "                        before = before.split(\",\")\n",
    "                        after = modified[1]\n",
    "                        after = after.replace(\"+\", \"\")\n",
    "                        after = after.split(\",\")\n",
    "                        # now our source files are after-modified\n",
    "\n",
    "                    if l.startswith(\"-\"):\n",
    "                        minus_count += 1\n",
    "                        minus_pos.append(j - start_line_num)\n",
    "\n",
    "                    if l.startswith(\"+\"):\n",
    "                        plus_count += 1\n",
    "                        plus_pos.append(j - start_line_num)\n",
    "                elif j < block_num:\n",
    "                    continue\n",
    "                else:\n",
    "                    block_num = j\n",
    "                    before = list(map(int, before))\n",
    "                    after = list(map(int, after))\n",
    "                    if len(archor) == 0:\n",
    "                        archor.append(\n",
    "                            [before, after, minus_count, plus_count, minus_pos, plus_pos, patch, after[0], minus_count,\n",
    "                             0])\n",
    "                    else:\n",
    "                        diff_value = archor[-1][8] + minus_count\n",
    "                        insert_after = after[0] + archor[-1][8]\n",
    "                        last_end = archor[-1][1][0] + archor[-1][1][1] - 1\n",
    "                        archor.append([before, after, minus_count, plus_count, minus_pos, plus_pos, patch, insert_after,\n",
    "                                       diff_value, last_end])\n",
    "                    break\n",
    "            else:\n",
    "                if block_num <= j < diff_start_line:\n",
    "                    patch.append(l)\n",
    "                    if l.startswith(\"@@ \"):\n",
    "                        start_line_num = j\n",
    "                        pos = l.find(\"@@ \")\n",
    "                        end = l.find(\" @@ \")\n",
    "                        modified = l[pos + 3:end]\n",
    "                        modified = modified.split(\" \")\n",
    "                        before = modified[0]\n",
    "                        before = before.replace(\"-\", \"\")\n",
    "                        before = before.split(\",\")\n",
    "                        after = modified[1]\n",
    "                        after = after.replace(\"+\", \"\")\n",
    "                        after = after.split(\",\")\n",
    "                        # now our source files are after-modified\n",
    "\n",
    "                    if l.startswith(\"-\"):\n",
    "                        minus_count += 1\n",
    "                        minus_pos.append(j - start_line_num)\n",
    "\n",
    "                    if l.startswith(\"+\"):\n",
    "                        plus_count += 1\n",
    "                        plus_pos.append(j - start_line_num)\n",
    "                elif j < block_num:\n",
    "                    continue\n",
    "                else:\n",
    "                    block_num = j\n",
    "                    before = list(map(int, before))\n",
    "                    after = list(map(int, after))\n",
    "                    if len(archor) == 0:\n",
    "                        archor.append(\n",
    "                            [before, after, minus_count, plus_count, minus_pos, plus_pos, patch, after[0], minus_count,\n",
    "                             0])\n",
    "                    else:\n",
    "                        diff_value = archor[-1][8] + minus_count\n",
    "                        insert_after = after[0] + archor[-1][8]\n",
    "                        last_end = archor[-1][1][0] + archor[-1][1][1] - 1\n",
    "                        archor.append([before, after, minus_count, plus_count, minus_pos, plus_pos, patch, insert_after,\n",
    "                                       diff_value, last_end])\n",
    "                    break\n",
    "\n",
    "    return archor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vulnerable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(file_content):\n",
    "    lines = file_content.splitlines()\n",
    "\n",
    "    vulnerable_function = []\n",
    "    skip_next_line_vuln = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Skip lines after `//fix_flaw_line_below:`\n",
    "        if \"//fix_flaw_line_below:\" in line:\n",
    "            skip_next_line_vuln = True\n",
    "            continue\n",
    "        if skip_next_line_vuln:\n",
    "            skip_next_line_vuln = False\n",
    "            continue\n",
    "\n",
    "        # Skip comments\n",
    "        if line.strip().startswith(\"//\"):\n",
    "            continue\n",
    "\n",
    "        # Add the line to the vulnerable function\n",
    "        vulnerable_function.append(line)\n",
    "\n",
    "    # Join the lines to get the final function code as a string\n",
    "    vulnerable_function_code = \"\\n\".join(vulnerable_function)\n",
    "    # print(vulnerable_function_code)\n",
    "\n",
    "    return vulnerable_function_code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non vulnerable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(file_content):\n",
    "    lines = file_content.splitlines()\n",
    "\n",
    "    non_vulnerable_function = []\n",
    "    skip_next_line_vuln = False\n",
    "    uncomment_next_line_fix = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Check if the line starts with `//flaw_line_below:`\n",
    "        if line.strip().startswith(\"//flaw_line_below:\"):\n",
    "            skip_next_line_vuln = True\n",
    "            continue\n",
    "\n",
    "        # If the previous line was `//flaw_line_below:`, skip this line\n",
    "        if skip_next_line_vuln:\n",
    "            skip_next_line_vuln = False\n",
    "            continue\n",
    "\n",
    "        # Check if the line starts with `//fix_flaw_line_below:`\n",
    "        if line.strip().startswith(\"//fix_flaw_line_below:\"):\n",
    "            uncomment_next_line_fix = True\n",
    "            continue\n",
    "\n",
    "        # If the previous line was `//fix_flaw_line_below:`, uncomment this line\n",
    "        if uncomment_next_line_fix:\n",
    "            uncomment_next_line_fix = False\n",
    "            non_vulnerable_function.append(line.lstrip(\"//\").strip() + \"\\n\")\n",
    "            continue\n",
    "\n",
    "        # Add the line to the non-vulnerable function\n",
    "        non_vulnerable_function.append(line)\n",
    "\n",
    "    # Join the lines to get the final function code as a string\n",
    "    non_vulnerable_function_code = \"\\n\".join(non_vulnerable_function)\n",
    "\n",
    "    return non_vulnerable_function_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patch_file(file_path):\n",
    "    non_vuln_lines = []\n",
    "    vuln_lines = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip()  # Remove any trailing newline or spaces\n",
    "\n",
    "            if line.startswith('+'):\n",
    "                non_vuln_lines.append(line[1:].strip())  # Remove the '+' symbol and any extra whitespace\n",
    "            elif line.startswith('-'):\n",
    "                vuln_lines.append(line[1:].strip())  # Remove the '-' symbol and any extra whitespace\n",
    "\n",
    "    return non_vuln_lines, vuln_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_code_lines(code):\n",
    "    vuln_lines = []\n",
    "    non_vuln_lines = []\n",
    "    \n",
    "    # Split the input code into lines\n",
    "    lines = code.split('\\n')\n",
    "    \n",
    "    is_vuln_next = False\n",
    "    is_fix_next = False\n",
    "    \n",
    "    for line in lines:\n",
    "        # Check if the current line indicates the next line is vulnerable\n",
    "        if \"//flaw_line_below\" in line:\n",
    "            is_vuln_next = True\n",
    "            continue\n",
    "        # Check if the current line indicates the next line is non-vulnerable\n",
    "        elif \"//fix_flaw_line_below\" in line:\n",
    "            is_fix_next = True\n",
    "            continue\n",
    "        \n",
    "        # If the flag is set, categorize the next line accordingly\n",
    "        if is_vuln_next:\n",
    "            vuln_lines.append(line.strip())\n",
    "            is_vuln_next = False\n",
    "        elif is_fix_next:\n",
    "            # Remove leading // and any extra spaces for non-vulnerable lines\n",
    "            non_vuln_lines.append(line.lstrip('/ ').strip())\n",
    "            is_fix_next = False\n",
    "\n",
    "    formatted_vuln_lines = \"\\n\".join(vuln_lines)\n",
    "    formatted_non_vuln_lines = \"\\n\".join(non_vuln_lines)\n",
    "\n",
    "    return formatted_vuln_lines, formatted_non_vuln_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line_diff(c_cpp_csv):\n",
    "    vul_number = 0 \n",
    "    data=[]\n",
    "\n",
    "    for index, row in tqdm(c_cpp_csv.iterrows(), total=len(c_cpp_csv)  , desc=\"Processing function with line extraction...\"):\n",
    "         try:   \n",
    "            commit_id = row[\"commit_id\"]    # commit id\n",
    "            diff = row[\"files_changed\"]\n",
    "            if not (row[\"cwe_id\"] is None) and not (row[\"cwe_id\"] == \"\"):\n",
    "                CWE_ID = str(row[\"cwe_id\"])\n",
    "            else:\n",
    "                CWE_ID = \"others\"\n",
    "            \n",
    "            files_changed = []     # files changed in this commit\n",
    "            project = row[\"project\"]     # project name\n",
    "            for i in diff.split(\"<_**next**_>\"):\n",
    "                files_changed.append(json.loads(i))\n",
    "\n",
    "            for file in files_changed:\n",
    "                file_with_dir = file[\"filename\"]      # file name with full path\n",
    "                pos = file_with_dir.rfind('/')\n",
    "                if pos > 0:\n",
    "                    filename = file_with_dir[pos + 1:]  # file name\n",
    "                    file_dir = commit_id + \"/\" + file_with_dir[:pos]\n",
    "                elif pos == 0:\n",
    "                    filename = file_with_dir[1:]\n",
    "                    file_dir = commit_id\n",
    "                else:\n",
    "                    filename = file_with_dir\n",
    "                    file_dir = commit_id\n",
    "                raw_url=file[\"raw_url\"]    # raw url\n",
    "                if \"patch\" in file:\n",
    "                    patch = file[\"patch\"]\n",
    "                else:\n",
    "                    patch = \"\"\n",
    "                type_pos = filename.find('.')\n",
    "                if type_pos > 0:\n",
    "                    only_name = filename[:type_pos]\n",
    "                    only_type = filename[type_pos + 1:]\n",
    "                else:\n",
    "                    only_name = filename\n",
    "                    only_type = \"not know\"\n",
    "                \n",
    "                sourcefiles = get_source_content(raw_url)       # get source code from raw url\n",
    "                if sourcefiles is not None:\n",
    "                   sourcefiles_str = sourcefiles.decode('utf-8') \n",
    "\n",
    "                # TODO: get sourcefiles from local\n",
    "\n",
    "                if not os.path.exists(\"patchAll0206/\" + only_type + '/' + project + '/' + CWE_ID + '/' + file_dir):\n",
    "                    os.makedirs(\"patchAll0206/\" + only_type + '/' + project + '/' + CWE_ID + '/' + file_dir)\n",
    "                sourcefile_dir = \"patchAll0206/\" + only_type + '/' + project + '/' + CWE_ID + '/' + file_dir + '/' + filename\n",
    "                # print(\"sourcefiledir\",sourcefile_dir)\n",
    "                patchfile_dir = \"patchAll0206/\" + only_type + '/' + project + '/' + CWE_ID + '/' + file_dir + '/' + only_name + '_' + 'patch.txt'\n",
    "                # print(\"patchfile_dir\",patchfile_dir)\n",
    "                with open(sourcefile_dir, \"w+\") as source_file, open(patchfile_dir, \"w+\") as patch_file:\n",
    "                    source_file.write(sourcefiles_str)\n",
    "                    patch_file.write(patch)\n",
    "                # TODO: get functions: if vul? not vul?\n",
    "                if only_type == \"c\":\n",
    "\n",
    "                    num = get_diff_num(patchfile_dir)     # get the number of diff blocks\n",
    "\n",
    "                    archors = get_diff_information(patchfile_dir, num)    # get the diff information\n",
    "\n",
    "                    block_num = 0\n",
    "                    block_total = len(archors)\n",
    "                    for archor in archors:\n",
    "                        block_num += 1\n",
    "                        del_line_pos = archor[4]\n",
    "                        add_line_pos = archor[5]\n",
    "                        patch_start = int(archor[1][0])\n",
    "                        patch_lines = int(archor[0][1]) + archor[3]\n",
    "                        patch_end = patch_start + patch_lines - 1\n",
    "                        source_end = patch_start + int(archor[1][1]) - 1\n",
    "                        last_end = archor[9]\n",
    "                        wrote = False\n",
    "\n",
    "                        add_patch_file_dir = \"patchAll0206/\" + only_type + '/' + project + '/' + CWE_ID + '/' + file_dir + '/' + \"add_patch_\" + filename\n",
    "                        with open(sourcefile_dir, \"r\") as before, open(add_patch_file_dir, \"a\") as after:\n",
    "                            lines = before.readlines()\n",
    "                            flen = len(lines)  # the number of lines in the source file\n",
    "                            for i in range(flen):\n",
    "                                if last_end - 1 < i <= source_end - 1:\n",
    "                                    if i == 0:\n",
    "                                        after.write(lines[i])\n",
    "                                        continue\n",
    "                                    if (patch_start - 1 <= i <= source_end - 1):\n",
    "                                        if wrote == False:\n",
    "                                            for patch_line in archor[6][1:]:\n",
    "                                                if patch_line.startswith(\"+\"):\n",
    "                                                    patch_line = patch_line.replace(\"+\", \"//fix_flaw_line_below:\\n//\",\n",
    "                                                                                     1)\n",
    "                                                if patch_line.startswith(\"-\"):\n",
    "                                                    patch_line = patch_line.replace(\"-\", \"//flaw_line_below:\\n\", 1)\n",
    "                                                if not patch_line.endswith(\"\\n\"):\n",
    "                                                    patch_line = patch_line + \"\\n\"\n",
    "                                                after.write(patch_line)\n",
    "                                            wrote = True\n",
    "                                    else:\n",
    "                                        after.write(lines[i])\n",
    "                                if block_num == block_total and source_end < flen and i > source_end - 1:\n",
    "                                    after.write(lines[i])\n",
    "\n",
    "                    line_nums = get_line_numbers(add_patch_file_dir, \"c\")\n",
    "                    if len(line_nums) > 0:\n",
    "                        for line_num in line_nums:\n",
    "                            code, i = process_file(add_patch_file_dir, line_num)    # get the function code and the end line number\n",
    "                            if \"//flaw_line_below:\" in code or \"//fix_flaw_line_below:\\n//\" in code:\n",
    "                                vuln_code = test(code)\n",
    "                                non_vuln_code =test2(code)\n",
    "                                vuln_line, non_vuln_line = categorize_code_lines(code)\n",
    "                                vul_number += 1\n",
    "                                split_vul_dir = \"./split0206/vul\" + '/' + project + '/' + CWE_ID\n",
    "                                if not os.path.exists(split_vul_dir):\n",
    "                                    os.makedirs(split_vul_dir)\n",
    "                                split_vul_file = split_vul_dir + '/' + CWE_ID + \"_\" + \"add_patch_\" + str(\n",
    "                                    i) + \"_\" + filename\n",
    "                                with open(split_vul_file, \"w+\") as vulFun:\n",
    "                                    vulFun.write(code)\n",
    "                                    \n",
    "                                split_vul_dir_0 = \"./split0206/vul0\" + '/' + project\n",
    "                                if not os.path.exists(split_vul_dir_0):\n",
    "                                    os.makedirs(split_vul_dir_0)\n",
    "                                split_vul_file_0 = split_vul_dir_0 + '/' + CWE_ID + \"_\"\"add_patch_\" + str(\n",
    "                                    i) + \"_\" + filename\n",
    "                                with open(split_vul_file_0, \"w+\") as vulFun0:\n",
    "                                    vulFun0.write(code)\n",
    "                                \n",
    "                                cve_id = row[\"cve_id\"]\n",
    "                                cwe_id = row[\"cwe_id\"]\n",
    "                                project = row[\"project\"]\n",
    "                                commit_id = row[\"commit_id\"]\n",
    "                                ref_link = row[\"ref_link\"]\n",
    "                                vulnerability_classification = row[\"vulnerability_classification\"]\n",
    "                                score=row[\"score\"]\n",
    "\n",
    "                                # result={\n",
    "                                #     \"cve_id\":cve_id,\n",
    "                                #     \"cwe_id\":cwe_id,\n",
    "                                #     \"commit_link\":ref_link,\n",
    "                                #     \"project\":project,\n",
    "                                #     \"commit_id\":commit_id,\n",
    "                                #     \"score\":score,\n",
    "                                #     \"language\":only_type,\n",
    "                                #     \"vulnerability_type\":vulnerability_classification,\n",
    "                                #     \"filename_with_path\":file_with_dir,\n",
    "                                #     \"vuln_line\":vuln_line,\n",
    "                                #     \"non_vuln_line\":non_vuln_line,\n",
    "                                #     \"vuln_function\":vuln_code,\n",
    "                                #     \"non_vuln_function\":non_vuln_code,\n",
    "                                #     \"filename\":filename,\n",
    "                                #     \"raw_url\":raw_url,\n",
    "                                # }\n",
    "                                # print(\"This is result\",result)\n",
    "                                # data.append(result)\n",
    "\n",
    "                                lines = code.split('\\n')\n",
    "\n",
    "                                # Extract flaw lines and fix flaw lines\n",
    "                                for i, line in enumerate(lines):\n",
    "                                    line_before=\"\"\n",
    "                                    line_after=\"\"\n",
    "                                    if \"//flaw_line_below:\" in line:\n",
    "                                        # assign value to line_before\n",
    "                                        line_before = lines[i + 1].strip() if i + 1 < len(lines) else \"\"\n",
    "                                        print(\"line_before\",line_before)\n",
    "\n",
    "                                        \n",
    "                                      \n",
    "                                     \n",
    "                                    elif \"//fix_flaw_line_below:\" in line:\n",
    "                                        # assign value to line_after\n",
    "                                        line_after = lines[i + 1].strip() if i + 1 < len(lines) else \"\"\n",
    "                                    # print(\"line_after\",line_after)\n",
    "\n",
    "                                # Ensure both lists have the same length by filling missing entries with \"Not Available\"\n",
    "                                # max_length = max(len(flaw_lines), len(fix_flaw_lines))\n",
    "                                # flaw_lines += [\"Not Available\"] * (max_length - len(flaw_lines))\n",
    "                                # fix_flaw_lines += [\"Not Available\"] * (max_length - len(fix_flaw_lines))\n",
    "                        \n",
    "                            else:\n",
    "                                split_nonevul_dir = \"./split0206/nonevul\" + '/' + project\n",
    "                                if not os.path.exists(split_nonevul_dir):\n",
    "                                    os.makedirs(split_nonevul_dir)\n",
    "                                split_nonevul_file = split_nonevul_dir + '/' + \"add_patch_\" + str(i) + \"_\" + filename\n",
    "                                with open(split_nonevul_file, \"w+\") as nonVulFun:\n",
    "                                    nonVulFun.write(code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         except Exception as e:\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "            print(\"reason\", e)\n",
    "            print(\"\\n commit_id:\" + str(commit_id) + \"！\")\n",
    "            print(\"\\n index:\" + str(index) + \"！\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('function_with_line.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    print('completed...')       \n",
    "    \n",
    "    print(\"vul_number\",vul_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing function with line extraction...: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before string->space = 1;\n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before string->space *= 2;\n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before if (string->space < 0)\n",
      "line_before \n",
      "line_before \n",
      "line_before g_warning (\"glyph string length overflows maximum integer size, truncated\");\n",
      "line_before \n",
      "line_before new_len = string->space = G_MAXINT - 8;\n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "line_before \n",
      "completed...\n",
      "vul_number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # delete dir patchAll0206\n",
    "    if os.path.exists(\"patchAll0206\"):\n",
    "        shutil.rmtree(\"patchAll0206\")\n",
    "    # delete dir split0206\n",
    "    if os.path.exists(\"split0206\"):\n",
    "        shutil.rmtree(\"split0206\")\n",
    "    c_cpp_csv = pd.read_csv('all_c_cpp_release2.0.csv', nrows=1,encoding='utf-8')\n",
    "    # c_cpp_csv = pd.read_csv('all_c_cpp_release2.0.csv',encoding='utf-8')\n",
    "    result=generate_line_diff(c_cpp_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
